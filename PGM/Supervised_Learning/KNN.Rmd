---
title: "KNN Balanced"
author: "Shannon Murphy"
date: "2/6/2023"
output: html_document
---

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 100px;
}
```

```{css, echo=FALSE}
.scroll-100 {
  max-height: 100px;
  overflow-y: auto;
  background-color: inherit;
}
```


```{r message=FALSE, warning=FALSE}
# Libraries
library(tidyverse)
library(class)
library(gmodels)

library(caret)
```


# All Variables 

## Data 
```{r}
# Loading in data from github
load("/Users/sdm98/Documents/GitHub/Private707/data/Balanced/ModelDev_Train_BalancedUSE.RData")
load("/Users/sdm98/Documents/GitHub/Private707/data/Balanced/FinalValidation_UnbalancedUSE.RData")

Train <- Train_Model_Dev_Balanced
Test <- final_test
```

```{r}
# Selecting clusters that are needed 
Train_All <- Train %>% select(-P28)
Train_sub12 <- Train %>% select(-P28) %>% dplyr::select(c(P49f,P49a,P50b,P49l,P26a,P34,P49h,P37,P47e,P45,P49i,P47b,SelfPerceivedHealth))

Train_sub5 <- Train %>% select(-P28) %>% dplyr::select(c(P49f,P49a,P50b,P37,P49l,SelfPerceivedHealth))

Test_All <- Test %>% select(-P28)
Test_sub12 <- Test %>% select(-P28) %>% dplyr::select(c(P49f,P49a,P50b,P49l,P26a,P34,P49h,P37,P47e,P45,P49i,P47b,SelfPerceivedHealth))
Test_sub5 <- Test %>% select(-P28) %>% dplyr::select(c(P49f,P49a,P50b,P37,P49l,SelfPerceivedHealth))

# Split x and y
x_train <- sapply(Train_All %>% select(-SelfPerceivedHealth),as.numeric)
x_train12 <- sapply(Train_sub12 %>% select(-SelfPerceivedHealth),as.numeric)
x_train5 <- sapply(Train_sub5 %>% select(-SelfPerceivedHealth),as.numeric)

x_test <- sapply(Test_All %>% select(-SelfPerceivedHealth), as.numeric)
x_test12 <- sapply(Test_sub12 %>% select(-SelfPerceivedHealth),as.numeric)
x_test5 <- sapply(Test_sub5 %>% select(-SelfPerceivedHealth),as.numeric)

y_train <- sapply(Train_All %>% select(SelfPerceivedHealth), as.numeric)
y_test <- sapply(Test %>% select(SelfPerceivedHealth),as.numeric)
```


## KNN

### All 
```{r}
#use cross validation to fit models
trControl <- trainControl(method  = "cv",
                          number  = 5)
set.seed(2023)
fit_all <- train(as.factor(SelfPerceivedHealth) ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k=c(5,10,sqrt(dim(Train_All)[1]),100)),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = cbind(y_train,x_train))

fit_all
```

```{r}
#get sensitivity/specificity
pred_train_all <- predict(fit_all, x_train)

CrossTable(pred_train_all, y_train, prop.chisq = FALSE)

ctab <- table(pred_train_all,y_train)

#accuracy = correct/total
acc <- (ctab[1,1] + ctab[2,2])/(ctab[1,1] + ctab[1,2] + ctab[2,1] + ctab[2,2])
acc

#sensitivity = true pos/(true pos + false neg)
sens <- ctab[2,2]/(ctab[2,2] + ctab[1,2])
sens

#specificity = true neg/(true neg + false neg)
spec <- ctab[1,1]/(ctab[1,1] + ctab[2,1])
spec

#error = 1 - accuracy
err <- 1-acc
err

#precision = true pos/(true pos + false pos)
prec <- ctab[2,2]/(ctab[2,2]+ctab[2,1])
prec
```


### Top 12 
```{r}
#use cross validation to fit models
trControl <- trainControl(method  = "cv",
                          number  = 5)
set.seed(2023)
fit_12 <- train(as.factor(SelfPerceivedHealth) ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k=c(5,10,sqrt(dim(Train_sub12)[1]),100)),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = cbind(y_train,x_train12))

fit_12
```

```{r}
#get sensitivity/specificity
pred_train_12 <- predict(fit_12, x_train12)

CrossTable(pred_train_12, y_train, prop.chisq = FALSE)

ctab12 <- table(pred_train_12,y_train)

#accuracy = correct/total
acc12 <- (ctab12[1,1] + ctab12[2,2])/(ctab12[1,1] + ctab12[1,2] + ctab12[2,1] + ctab12[2,2])
acc12

#sensitivity = true pos/(true pos + false neg)
sens12 <- ctab12[2,2]/(ctab12[2,2] + ctab12[1,2])
sens12

#specificity = true neg/(true neg + false neg)
spec12 <- ctab12[1,1]/(ctab12[1,1] + ctab12[2,1])
spec12

#error = 1 - accuracy
err12 <- 1-acc12
err12

#precision = true pos/(true pos + false pos)
prec12 <- ctab12[2,2]/(ctab12[2,2]+ctab12[2,1])
prec12
```

### Top 5 
```{r}
#use cross validation to fit models
trControl <- trainControl(method  = "cv",
                          number  = 5)
set.seed(2023)
fit_5 <- train(as.factor(SelfPerceivedHealth) ~ .,
             method     = "knn",
             tuneGrid   = expand.grid(k=c(5,10,sqrt(dim(Train_sub5)[1]),100)),
             trControl  = trControl,
             metric     = "Accuracy",
             data       = cbind(y_train,x_train5))

fit_5
```

```{r}
#get sensitivity/specificity
pred_train_5 <- predict(fit_5, x_train5)

CrossTable(pred_train_5, y_train, prop.chisq = FALSE)

ctab5 <- table(pred_train_5,y_train)

#accuracy = correct/total
acc5 <- (ctab5[1,1] + ctab5[2,2])/(ctab5[1,1] + ctab5[1,2] + ctab5[2,1] + ctab5[2,2])
acc5

#sensitivity = true pos/(true pos + false neg)
sens5 <- ctab5[2,2]/(ctab5[2,2] + ctab5[1,2])
sens5

#specificity = true neg/(true neg + false neg)
spec5 <- ctab5[1,1]/(ctab5[1,1] + ctab5[2,1])
spec5

#error = 1 - accuracy
err5 <- 1-acc5
err5

#precision = true pos/(true pos + false pos)
prec5 <- ctab5[2,2]/(ctab5[2,2]+ctab5[2,1])
prec5
```


## Training Set Results
```{r}
data.frame(model = c('All','Top 12','Top 5'),accuracy = c(acc, acc12, acc5), sensitivity = c(sens, sens12, sens5), specificity = c(spec, spec12, spec5), precision = c(prec, prec12, prec5))
```