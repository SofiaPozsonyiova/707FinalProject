---
title: "RF_BalancedTrain_CV"
author: "Sofia Pozsonyiova"
date: "2/16/2023"
output: html_document
---

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 100px;
}
```

```{css, echo=FALSE}
.scroll-100 {
  max-height: 100px;
  overflow-y: auto;
  background-color: inherit;
}
```


```{r message=FALSE, warning=FALSE}
set.seed(707)
# Libraries
library(ggplot2)
library(gridExtra)
library(dplyr)
library(caret)
library(rpart)         
library(rpart.plot)    
library(class)         
library(randomForest)  
library(infer)
library(pander)
```

# Data 

```{r}
# Loading in data from github
# Training 
load("/Users/sofiapozsonyiova/Documents/GitHub/Private707/data/2022/ModelDev_Train_BalancedUSE.RData")

# Testing 
load("/Users/sofiapozsonyiova/Documents/GitHub/Private707/data/2022/FinalValidation_UnbalancedUSE.RData")
```


# All Variables: CV 

## Data 

```{r}
# Selecting clusters that are needed 
Train_All <- Train_Model_Dev_Balanced 

factor_vars <- Train_All %>% dplyr::select(c(-SelfPerceivedHealth))
fac_col_names <- names(factor_vars)

Train_All[,fac_col_names] <- lapply(Train_All[,fac_col_names] , as.numeric)
Train_All <- Train_All %>% mutate(SelfPerceivedHealth = as.factor(SelfPerceivedHealth))




factor_varsTEST <- final_test %>% dplyr::select(c(-SelfPerceivedHealth))
fac_col_namesTEST  <- names(factor_varsTEST)

final_test[,fac_col_namesTEST] <- lapply(final_test[,fac_col_namesTEST] , as.numeric)
final_test <- final_test %>% mutate(SelfPerceivedHealth = as.factor(SelfPerceivedHealth))
```

### Training: All Variables Included  
```{r cache=TRUE}
## Set seed for reproducibility
set.seed(2023)

# Initializing Random Forest
forest_modelAll <- train(
  SelfPerceivedHealth ~ ., 
  data = Train_All,
  method = "rf",
  tuneGrid = data.frame(mtry = c(12)),
  trControl = trainControl(method = "cv",number = 5),
  metric = "Accuracy",
  na.action = na.omit)

```

```{r}
# Printing results
print(forest_modelAll)
forest_modelAll$results
```

```{r}
# #Visualizing results 
# plot(forest_modelAll)
```

```{r}
# Final model Forest 
forest_modelAll$finalModel
```

```{r}
## Get variable importance, and turn into a data frame
var_impAll <- varImp(forest_modelAll, scale=FALSE)$importance
var_impAll <- data.frame(variables=row.names(var_impAll), importance=var_impAll$Overall)
var_impAll %>% arrange(desc(importance))
```


```{r fig.height=12}
## Create a plot of variable importance
var_impAll <- var_impAll %>%
  arrange(importance) %>%
  ggplot(aes(x=reorder(variables, importance), y=importance)) + 
  geom_bar(stat='identity', fill = "cornflowerblue") + 
  coord_flip() + 
  xlab('Variables') +
  labs(title='Random Forest Variable Importance (All predictors)') + ylab("Gini Impurity") + 
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14))
#ggsave("/Users/sofiapozsonyiova/Documents/GitHub/707FinalProject/PGM/Model\ Building/var_impAll.png")

var_impAll
```

```{r}
## Generate predictions
y_hatsAll_val <- predict(
  object=forest_modelAll, 
  newdata= Train_All %>% select(-SelfPerceivedHealth))

## Print the accuracy
accuracy <- mean(y_hatsAll_val == Train_All$SelfPerceivedHealth)*100
cat('Accuracy on testing data: ', round(accuracy, 2), '%',  sep='')
```

```{r}
# Confusion matrix 
conf_all_final <- table(Train_All$SelfPerceivedHealth, y_hatsAll_val)
conf_all_final

confusionMatrix(table(Train_All$SelfPerceivedHealth, y_hatsAll_val))
```


### Validation Set: All Variables Included  
```{r}
## Generate predictions
y_hatsAll_val <- predict(
  object=forest_modelAll, 
  newdata= final_test %>% select(-SelfPerceivedHealth))

## Print the accuracy
accuracy <- mean(y_hatsAll_val == final_test$SelfPerceivedHealth)*100
cat('Accuracy on testing data: ', round(accuracy, 2), '%',  sep='')
```

```{r}
# Confusion matrix 
conf_all_final <- table(final_test$SelfPerceivedHealth, y_hatsAll_val)
conf_all_final

confusionMatrix(table(final_test$SelfPerceivedHealth, y_hatsAll_val))
```


# Top 12 Variables: CV

P50b	348.0440210			
P49a	250.7617614			
P49f	247.8041733			
P49l	189.0953441			
P49h	157.6218958			
Suicide	148.6688634			
P37	130.4934373			
P50c	124.8739970			
P34	114.7006453			
P26a	112.1956793	
P50d	110.4604551			
P49e	100.5335619	

## Data 
```{r}
Train_sub12 <- Train_All  %>% dplyr::select(c(SelfPerceivedHealth,P50b,P49a,P49f,P49l,P49h,Suicide,P37,P50c,P34,P26a,P50d,P49e))
```

### Training: All Variables Included  
```{r cache = TRUE}
# Initializing Random Forest
forest_model_12 <- train(
  SelfPerceivedHealth ~ ., 
  data = Train_sub12,
  method = "rf",
  tuneGrid = data.frame(mtry = c(2,4,6,12)),
  trControl = trainControl(method = "cv",number = 5),
  metric = "Accuracy",
  na.action = na.omit,
  seed = 2023)
```

```{r}
# Printing results
print(forest_model_12)
forest_model_12$results
```

```{r}
#Visualizing results 
plot(forest_model_12)
```

```{r}
# Final model Forest 
forest_model_12$finalModel
```

```{r}
## Get variable importance, and turn into a data frame
var_imp12 <- varImp(forest_model_12, scale=FALSE)$importance
var_imp12 <- data.frame(variables=row.names(var_imp12), importance=var_imp12$Overall)
var_imp12 %>% arrange(desc(importance))
```


```{r fig.height=12}
## Create a plot of variable importance
var_imp12 <- var_imp12 %>%
  arrange(importance) %>%
  ggplot(aes(x=reorder(variables, importance), y=importance)) + 
  geom_bar(stat='identity', fill = "cornflowerblue") + 
  coord_flip() + 
  xlab('Variables') +
  labs(title='Random Forest Variable Importance (All predictors)') + ylab("Gini Impurity") + 
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14))
#ggsave("/Users/sofiapozsonyiova/Documents/GitHub/707FinalProject/PGM/Model\ Building/var_impAll.png")

var_imp12
```

```{r}
## Generate predictions
y_hats12 <- predict(
  object=forest_model_12, 
  newdata= Train_sub12 %>% select(-SelfPerceivedHealth))

## Print the accuracy
accuracy <- mean(y_hats12 == Train_sub12$SelfPerceivedHealth)*100
cat('Accuracy on testing data: ', round(accuracy, 2), '%',  sep='')
```

```{r}
# Confusion matrix 
conf_12 <- table(Train_sub12$SelfPerceivedHealth, y_hats12)
conf_12

confusionMatrix(table(Train_sub12$SelfPerceivedHealth, y_hats12))
```

### Validation Set: Top 12 

```{r}
## Generate predictions
y_hats12 <- predict(
  object=forest_model_12, 
  newdata= final_test %>% select(-SelfPerceivedHealth))

## Print the accuracy
accuracy <- mean(y_hats12 == final_test$SelfPerceivedHealth)*100
cat('Accuracy on testing data: ', round(accuracy, 2), '%',  sep='')
```

```{r}
# Confusion matrix 
conf_12 <- table(final_test$SelfPerceivedHealth, y_hats12)
conf_12

confusionMatrix(table(final_test$SelfPerceivedHealth, y_hats12))
```

		

# Top 5 Variables: CV

P50b	754.4766			
P49f	569.5484			
P49a	568.8003			
P37	499.5082			
P49l	448.0862	
## Data 
```{r}
Train_sub5 <- Train_All  %>% dplyr::select(c(P49f,P49a,P50b,P37,P49l,SelfPerceivedHealth))
```

### Training: All Variables Included  
```{r cache = TRUE}
# Initializing Random Forest
forest_model_5 <- train(
  SelfPerceivedHealth ~ ., 
  data = Train_sub5,
  method = "rf",
  tuneGrid = data.frame(mtry = c(1,2,4,5)),
  trControl = trainControl(method = "cv",number = 5),
  metric = "Accuracy",
  na.action = na.omit,
  seed = 2023)
```

```{r}
# Printing results
print(forest_model_5)
forest_model_5$results
```

```{r}
#Visualizing results 
plot(forest_model_5)
```

```{r}
# Final model Forest 
forest_model_5$finalModel
```

```{r}
## Get variable importance, and turn into a data frame
var_imp5 <- varImp(forest_model_5, scale=FALSE)$importance
var_imp5 <- data.frame(variables=row.names(var_imp5), importance=var_imp5$Overall)
var_imp5 %>% arrange(desc(importance))
```

```{r fig.height=12}
## Create a plot of variable importance
var_imp5 <- var_imp5 %>%
  arrange(importance) %>%
  ggplot(aes(x=reorder(variables, importance), y=importance)) + 
  geom_bar(stat='identity', fill = "cornflowerblue") + 
  coord_flip() + 
  xlab('Variables') +
  labs(title='Random Forest Variable Importance (All predictors)') + ylab("Gini Impurity") + 
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14))
#ggsave("/Users/sofiapozsonyiova/Documents/GitHub/707FinalProject/PGM/Model\ Building/var_impAll.png")

var_imp5
```

```{r}
## Generate predictions
y_hats5 <- predict(
  object=forest_model_5, 
  newdata= Train_sub5 %>% select(-SelfPerceivedHealth))

## Print the accuracy
accuracy <- mean(y_hats5 == Train_sub5$SelfPerceivedHealth)*100
cat('Accuracy on testing data: ', round(accuracy, 2), '%',  sep='')
```

```{r}
# Confusion matrix 
conf_5 <- table(Train_sub5$SelfPerceivedHealth, y_hats5)
conf_5

confusionMatrix(table(Train_sub5$SelfPerceivedHealth, y_hats5))
```




### Validation Set: Top 5

```{r}
## Generate predictions
y_hats5 <- predict(
  object=forest_model_5, 
  newdata= final_test %>% select(-SelfPerceivedHealth))

## Print the accuracy
accuracy <- mean(y_hats5 == final_test$SelfPerceivedHealth)*100
cat('Accuracy on testing data: ', round(accuracy, 2), '%',  sep='')
```

```{r}
# Confusion matrix 
conf_5 <- table(final_test$SelfPerceivedHealth, y_hats5)
conf_5

confusionMatrix(table(final_test$SelfPerceivedHealth, y_hats5))
```


# Logistic Regression 
```{r}
load("/Users/sofiapozsonyiova/Documents/GitHub/Private707/data/Balanced/FULL2022_Subset.RData")
load("/Users/sofiapozsonyiova/Documents/GitHub/Private707/data/SubsetDat.RData")


factor_varsTEST <- Full2019 %>% dplyr::select(c(-SelfPerceivedHealth))
fac_col_namesTEST  <- names(factor_varsTEST)

Full2019[,fac_col_namesTEST] <- lapply(Full2019[,fac_col_namesTEST] , as.numeric)
Full2019 <- Full2019 %>% mutate(SelfPerceivedHealth = as.factor(SelfPerceivedHealth))

glimpse(Full2019)

Train_sub5 <- Train %>% select(-P28) %>% dplyr::select(c(P49f,P49a,P50b,P37,P49l,SelfPerceivedHealth))
```

```{r}
set.seed(2023)

# Create model with all variables as predictors
trControl <- trainControl(method = "cv",
                          number = 5)
log_reg_5 <- train(as.factor(SelfPerceivedHealth) ~ P49f+P49a+P50b+P37+P49l,
                   method = "glm",
                   family = binomial(),
                   trControl = trControl,
                   metric = "Accuracy",
                   data = Full2019)

summary(log_reg_5) %>% pander()

# Get odds ratios for all coefficients
exp(coef(log_reg_5$finalModel))

# Get confidence intervals
exp(confint(log_reg_5$finalModel))

# Predict on train data
predicted_5 <- stats::predict(log_reg_5, na_removed_dat)
predicted_5

# Run confusion matrix
caret::confusionMatrix(predicted_5, as.factor(na_removed_dat$SelfPerceivedHealth))

```

